# @package training.optimizer
name: adam-atan2 # adamw
params:
  weight_decay: 1.0
  betas: [0.9, 0.95]
